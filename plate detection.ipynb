{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.datasets import LoadImages\n",
    "from utils.general import (check_file, check_img_size, increment_path, non_max_suppression, scale_coords, clip_coords,\n",
    "                          xywh2xyxy, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors\n",
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = False\n",
    "augment=False\n",
    "visualize=False\n",
    "classes=None  \n",
    "agnostic_nms=False \n",
    "save_img = True\n",
    "save_crop = True\n",
    "view_img = True\n",
    "hide_labels = False\n",
    "hide_conf = False\n",
    "\n",
    "conf_thres=0.25  \n",
    "iou_thres=0.45  \n",
    "max_det=1000\n",
    "line_thickness = 2\n",
    "\n",
    "image_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_box2(xyxy, im, file='image.jpg', gain=1.02, pad=0, square=False, BGR=False, save=True):\n",
    "    xyxy = torch.tensor(xyxy).view(-1, 4)\n",
    "    boxes = xyxy2xywh(xyxy)\n",
    "    if square:\n",
    "        boxes[:, 2:] =boxes[:, 2:].max(1)[0].unsqueeze(1)\n",
    "    boxes[:, 2:] = boxes[:, 2:] * gain + pad #box wh * gain + pad\n",
    "    xyxy = xywh2xyxy(boxes).long()\n",
    "    clip_coords(xyxy, im.shape)\n",
    "    crop = im[int(xyxy[0, 1]):int(xyxy[0, 3]), int(xyxy[0, 0]):int(xyxy[0, 2]), ::(1 if BGR else -1)]\n",
    "    \n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "device = select_device('cpu')\n",
    "weights = 'models/best.pt'\n",
    "\n",
    "model = DetectMultiBackend(weights, device=device, dnn=False)\n",
    "stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
    "img_size = check_img_size(640, s=stride) #check image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ''\n",
    "source = check_file(source)\n",
    "save_dir = Path('')\n",
    "\n",
    "# Half\n",
    "half &= (pt or jit or engine) and device.type != 'cpu'\n",
    "if pt or jit:\n",
    "    model.model.half() if half else model.model.float()\n",
    "    \n",
    "dataset = LoadImages(source, img_size=img_size, stride=stride, auto=pt)\n",
    "batch_size = 1\n",
    "vid_path, vid_writer = [None] * batch_size, [None] * batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
